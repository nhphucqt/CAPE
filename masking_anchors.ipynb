{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a2a4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xtcocotools.coco import COCO\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from shapely.geometry import Point, Polygon\n",
    "from scipy.spatial import Delaunay\n",
    "import msgpack\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a469907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from EdgeCape.models.keypoint_heads.refine_head import RefineHead\n",
    "\n",
    "refine_head = RefineHead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = [\n",
    "    'capeformer',\n",
    "    'graphcape',\n",
    "    'edgecape',\n",
    "]\n",
    "\n",
    "MASK_PERCENTS = [\n",
    "    \"\",\n",
    "    \"_m25p\",\n",
    "    \"_m50p\",\n",
    "    \"_m75p\",\n",
    "    # \"_m65p\",\n",
    "    \"_m90p\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fd91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300000/300000 [07:08<00:00, 700.23it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"graphcape\"\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    for mask_percent in MASK_PERCENTS:\n",
    "        file_name = f\"result_voronoi_{model_name}_s1_5_1_300k_prototype_ori{mask_percent}\"\n",
    "        out_name = f\"result_voronoi_ref_{model_name}_s1_5_1_300k_prototype_ori{mask_percent}\"\n",
    "        if not Path(f\"{out_name}.msgpack\").exists():\n",
    "            print(f\"{file_name} does not exist, skip\")\n",
    "            continue\n",
    "        print(f\"Processing {file_name} -> {out_name}\")\n",
    "        with open(f\"result_records_msgpack/{file_name}.msgpack\", \"rb\") as f:\n",
    "            result_keypoints = msgpack.load(f)\n",
    "\n",
    "        for result in tqdm(result_keypoints):\n",
    "            # target_s\n",
    "            # preds\n",
    "            # coarse\n",
    "            # mask_s\n",
    "            target_s = np.array(result[\"target_s\"])[None]\n",
    "            preds = np.array(result[\"pred\"])[None, None]\n",
    "            coarse = np.array([1.0] * 68 + [0.0] * 5)[None]\n",
    "            if \"mask\" not in result:\n",
    "                mask_s = np.array([1.0] * 73)[None].astype(np.float32)\n",
    "            else:\n",
    "                mask_s = np.array(result[\"mask\"])[None].astype(np.float32)\n",
    "\n",
    "            # print(mask_s)\n",
    "\n",
    "            target_s = torch.tensor(target_s).float()\n",
    "            preds = torch.tensor(preds).float()\n",
    "            coarse = torch.tensor(coarse).float()\n",
    "            mask_s = torch.tensor(mask_s).float()\n",
    "\n",
    "            # print(target_s.shape, preds.shape, coarse.shape, mask_s.shape)\n",
    "            # print(mask_s)\n",
    "\n",
    "            # print(preds[0].squeeze(0).numpy()[68:])\n",
    "            out = refine_head(target_s, preds, coarse, mask_s)\n",
    "            # print(out[0].squeeze(0).numpy()[68:])\n",
    "            # print(out[-1].squeeze(0).numpy().shape)\n",
    "            result[\"pred\"] = out[-1].squeeze(0).numpy().tolist()\n",
    "\n",
    "        with open(f\"{out_name}.msgpack\", \"wb\") as f:\n",
    "            msgpack.dump(result_keypoints, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2a487cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 300000\n",
      "PCK@0.05: 0.40851666666666664\n",
      "PCK@0.1: 0.7844300000000001\n",
      "PCK@0.15: 0.9421733333333331\n",
      "PCK@0.2: 0.9898653333333328\n",
      "PCK@0.25: 0.9984293333333335\n"
     ]
    }
   ],
   "source": [
    "start_kpts_idx = 68\n",
    "threshold_list = [.05, .1, .15, .2, .25]\n",
    "acc = {}\n",
    "for threshold in threshold_list:\n",
    "    acc[threshold] = []\n",
    "print(\"Total images:\", len(result_keypoints))\n",
    "for id, result in enumerate(result_keypoints):\n",
    "    gt = np.array(result['gt'])[start_kpts_idx:]\n",
    "    pred = np.array(result['pred'])[start_kpts_idx:]\n",
    "    if 'mask' in result:\n",
    "        mask = np.array(result['mask'])[start_kpts_idx:]\n",
    "    else:\n",
    "        mask = np.ones_like(gt[:, 0]).astype(bool)\n",
    "    # gt = np.array(result['gt'])[:start_kpts_idx]\n",
    "    # pred = np.array(result['pred'])[:start_kpts_idx]\n",
    "    bbox = np.array(result['bbox'])\n",
    "    max_side = max(bbox[2], bbox[3])\n",
    "    # error = np.linalg.norm(gt - pred, axis=1) / max_side\n",
    "    error = np.linalg.norm((gt - pred) / max_side, axis=1)[mask]\n",
    "    if np.sum(error > 1000) > 0:\n",
    "        print(f\"Warning: image {id} has {np.sum(error > 1000)} keypoints with error > 1000\")\n",
    "        continue\n",
    "    for threshold in threshold_list:\n",
    "        acc[threshold].append((error < threshold).mean())\n",
    "for threshold in threshold_list:\n",
    "    print(f\"PCK@{threshold}:\", np.mean(acc[threshold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8807cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{out_name}.msgpack\", \"wb\") as f:\n",
    "    msgpack.dump(result_keypoints, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab254ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total images: 300000\n",
    "# PCK@0.05: 0.9294966666666669\n",
    "# PCK@0.1: 0.9965980000000001\n",
    "# PCK@0.15: 0.9995073333333334\n",
    "# PCK@0.2: 0.9998466666666669\n",
    "# PCK@0.25: 0.9999300000000002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59abb052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
